{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Convolutional Neural Networks on PYNQ\n",
    "\n",
    "Let's use the same quantized and pruned model as in the CNN tutorial (part6_cnns.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Start with the neccessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Fetch the SVHN dataset using Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 73257 samples of input shape (32, 32, 3), belonging to 10 classes\n"
     ]
    }
   ],
   "source": [
    "ds_train, info = tfds.load('svhn_cropped', split='train[:90%]', with_info=True, as_supervised=True,data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\")\n",
    "ds_test        = tfds.load('svhn_cropped', split='test', shuffle_files=True, as_supervised=True,data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\")\n",
    "ds_val         = tfds.load('svhn_cropped', split='train[-10%:]', shuffle_files=True, as_supervised=True,data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\")\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "train_size  = int(info.splits['train'].num_examples)\n",
    "input_shape = info.features['image'].shape \n",
    "n_classes   = info.features['label'].num_classes \n",
    "\n",
    "print('Training on {} samples of input shape {}, belonging to {} classes'.format(train_size,input_shape,n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label,nclasses=10):\n",
    "  image = tf.cast(image, tf.float32) / 255.\n",
    "  label = tf.one_hot(tf.squeeze(label), nclasses)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train batch shape = (1024, 32, 32, 3), Y train batch shape = (1024, 10) \n",
      "X test batch shape = (26032, 32, 32, 3), Y test batch shape = (26032, 10) \n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_data = ds_train.map(preprocess,n_classes) #Get dataset as image and one-hot encoded labels, divided by max RGB   \n",
    "train_data = train_data.shuffle(4096).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for example in train_data.take(1):\n",
    "    break\n",
    "print(\"X train batch shape = {}, Y train batch shape = {} \".format(example[0].shape, example[1].shape))\n",
    "\n",
    "val_data = ds_val.map(preprocess,n_classes)    \n",
    "val_data = val_data.batch(batch_size)\n",
    "val_data = val_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# For  testing, we get the full dataset in memory as it's rather small.\n",
    "# We fetch it as numpy arrays to have access to labels and images separately\n",
    "X_test, Y_test = tfds.as_numpy(tfds.load('svhn_cropped',split='test',batch_size=-1,as_supervised=True,data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\"))\n",
    "X_test, Y_test = preprocess(X_test, Y_test,nclasses=n_classes)\n",
    "print(\"X test batch shape = {}, Y test batch shape = {} \".format(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a quantized and pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fused QConv+BN block 0 with N=16 filters\n",
      "Adding fused QConv+BN block 1 with N=16 filters\n",
      "Adding fused QConv+BN block 2 with N=24 filters\n",
      "Adding QDense block 0 with N=42 neurons\n",
      "Adding QDense block 1 with N=64 neurons\n",
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "fused_convbn_0 (QConv2DBatch (None, 30, 30, 16)        513       \n",
      "_________________________________________________________________\n",
      "conv_act_0 (QActivation)     (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "pool_0 (MaxPooling2D)        (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "fused_convbn_1 (QConv2DBatch (None, 13, 13, 16)        2385      \n",
      "_________________________________________________________________\n",
      "conv_act_1 (QActivation)     (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "fused_convbn_2 (QConv2DBatch (None, 4, 4, 24)          3577      \n",
      "_________________________________________________________________\n",
      "conv_act_2 (QActivation)     (None, 4, 4, 24)          0         \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 2, 2, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_0 (QDense)             (None, 42)                4032      \n",
      "_________________________________________________________________\n",
      "bn_dense_0 (BatchNormalizati (None, 42)                168       \n",
      "_________________________________________________________________\n",
      "dense_act_0 (QActivation)    (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 64)                2688      \n",
      "_________________________________________________________________\n",
      "bn_dense_1 (BatchNormalizati (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_act_1 (QActivation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_dense (Dense)         (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "output_softmax (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 14,269\n",
      "Trainable params: 13,942\n",
      "Non-trainable params: 327\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "filters_per_conv_layer = [16,16,24]\n",
    "neurons_per_dense_layer = [42,64]\n",
    "\n",
    "x = x_in = Input(shape=input_shape)\n",
    "\n",
    "for i,f in enumerate(filters_per_conv_layer):\n",
    "    print( ('Adding fused QConv+BN block {} with N={} filters').format(i,f) )\n",
    "    x = QConv2DBatchnorm(int(f), kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(6,0,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=True,\n",
    "                         name='fused_convbn_{}'.format(i))(x) \n",
    "    x = QActivation('quantized_relu(6)',name='conv_act_%i'%i)(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2),name='pool_{}'.format(i) )(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for i,n in enumerate(neurons_per_dense_layer):\n",
    "  print( ('Adding QDense block {} with N={} neurons').format(i,n) )\n",
    "  x = QDense(n,\n",
    "            kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "            kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001),name='dense_%i'%i, use_bias=False)(x)\n",
    "  x = BatchNormalization(name='bn_dense_{}'.format(i))(x)\n",
    "  x = QActivation('quantized_relu(6)',name='dense_act_%i'%i)(x)\n",
    "x = Dense(int(n_classes),\n",
    "           name='output_dense')(x)\n",
    "x_out = Activation('softmax',name='output_softmax')(x)\n",
    "qmodel = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fused_convbn_0       f=16 quantized_bits(6,0,0,alpha=1) quantized_bits(6,0,0,alpha=1) \n",
      "conv_act_0           quantized_relu(6)\n",
      "fused_convbn_1       f=16 quantized_bits(6,0,0,alpha=1) quantized_bits(6,0,0,alpha=1) \n",
      "conv_act_1           quantized_relu(6)\n",
      "fused_convbn_2       f=24 quantized_bits(6,0,0,alpha=1) quantized_bits(6,0,0,alpha=1) \n",
      "conv_act_2           quantized_relu(6)\n",
      "dense_0              u=42 quantized_bits(6,0,0,alpha=1) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(6)\n",
      "dense_1              u=64 quantized_bits(6,0,0,alpha=1) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the quantized layers\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "print_qmodel_summary(qmodel)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps per epoch is 64\n",
      "WARNING:tensorflow:From /mnt/data/thaarres/miniconda3/envs/hls4ml-pynq-tutorial/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:207: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/data/thaarres/miniconda3/envs/hls4ml-pynq-tutorial/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:207: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "\n",
    "NSTEPS = int(train_size*0.9)  // batch_size #90% train, 10% validation in 10-fold cross validation\n",
    "print('Number of training steps per epoch is {}'.format(NSTEPS))\n",
    "\n",
    "# Prune all convolutional and dense layers gradually from 0 to 50% sparsity every 2 epochs, \n",
    "# ending by the 10th epoch\n",
    "def pruneFunction(layer):\n",
    "    pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity = 0.0,\n",
    "                                                                   final_sparsity = 0.50, \n",
    "                                                                   begin_step = NSTEPS*2, \n",
    "                                                                   end_step = NSTEPS*10, \n",
    "                                                                   frequency = NSTEPS)\n",
    "                     }\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "      return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name!='output_dense':\n",
    "      return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)  \n",
    "    return layer\n",
    "\n",
    "qmodel_pruned = tf.keras.models.clone_model( qmodel, clone_function=pruneFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "\n",
    "n_epochs = 30\n",
    "if train:\n",
    "    LOSS        = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True) \n",
    "    qmodel_pruned.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "            pruning_callbacks.UpdatePruningStep()\n",
    "            ]  \n",
    "\n",
    "    start = time.time()\n",
    "    history = qmodel_pruned.fit(train_data,\n",
    "                          epochs = n_epochs,\n",
    "                          validation_data = val_data,\n",
    "                          callbacks = callbacks, \n",
    "                          verbose=1)     \n",
    "    end = time.time()\n",
    "    print('\\n It took {} minutes to train!\\n'.format( (end - start)/60.))\n",
    "\n",
    "    qmodel_pruned.save('pynq_cnn_model.h5')\n",
    "\n",
    "else:\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "    \n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n",
    "    qmodel_pruned = tf.keras.models.load_model('pynq_cnn_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make bitfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "model = tf.keras.models.load_model('pynq_cnn_model.h5',custom_objects={'PruneLowMagnitude': pruning_wrapper.PruneLowMagnitude,\n",
    "                                                                         'QDense': QDense, \n",
    "                                                                         'QConv2DBatchnorm': QConv2DBatchnorm, \n",
    "                                                                         'QActivation': QActivation})\n",
    "model  = strip_pruning(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: fused_convbn_0, layer type: QConv2DBatchnorm\n",
      "Layer name: conv_act_0, layer type: QActivation\n",
      "Layer name: pool_0, layer type: MaxPooling2D\n",
      "Layer name: fused_convbn_1, layer type: QConv2DBatchnorm\n",
      "Layer name: conv_act_1, layer type: QActivation\n",
      "Layer name: pool_1, layer type: MaxPooling2D\n",
      "Layer name: fused_convbn_2, layer type: QConv2DBatchnorm\n",
      "Layer name: conv_act_2, layer type: QActivation\n",
      "Layer name: pool_2, layer type: MaxPooling2D\n",
      "Layer name: dense_0, layer type: QDense\n",
      "Layer name: bn_dense_0, layer type: BatchNormalization\n",
      "Layer name: dense_act_0, layer type: QActivation\n",
      "Layer name: dense_1, layer type: QDense\n",
      "Layer name: bn_dense_1, layer type: BatchNormalization\n",
      "Layer name: dense_act_1, layer type: QActivation\n",
      "Layer name: output_dense, layer type: Dense\n",
      "  -> Activation (linear), layer name: output_dense\n",
      "Layer name: output_softmax, layer type: Activation\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, current shape: [[None, 32, 32, 3]]\n",
      "Layer name: fused_convbn_0, layer type: QConv2DBatchnorm, current shape: [[None, 32, 32, 3]]\n",
      "Name: quantized_relu\n",
      "Layer name: conv_act_0, layer type: Activation, current shape: [[None, 30, 30, 16]]\n",
      "Layer name: pool_0, layer type: MaxPooling2D, current shape: [[None, 30, 30, 16]]\n",
      "Layer name: fused_convbn_1, layer type: QConv2DBatchnorm, current shape: [[None, 15, 15, 16]]\n",
      "Name: quantized_relu\n",
      "Layer name: conv_act_1, layer type: Activation, current shape: [[None, 13, 13, 16]]\n",
      "Layer name: pool_1, layer type: MaxPooling2D, current shape: [[None, 13, 13, 16]]\n",
      "Layer name: fused_convbn_2, layer type: QConv2DBatchnorm, current shape: [[None, 6, 6, 16]]\n",
      "Name: quantized_relu\n",
      "Layer name: conv_act_2, layer type: Activation, current shape: [[None, 4, 4, 24]]\n",
      "Layer name: pool_2, layer type: MaxPooling2D, current shape: [[None, 4, 4, 24]]\n",
      "Layer name: dense_0, layer type: QDense, current shape: [[None, 96]]\n",
      "Layer name: bn_dense_0, layer type: BatchNormalization, current shape: [[None, 42]]\n",
      "Name: quantized_relu\n",
      "Layer name: dense_act_0, layer type: Activation, current shape: [[None, 42]]\n",
      "Layer name: dense_1, layer type: QDense, current shape: [[None, 42]]\n",
      "Layer name: bn_dense_1, layer type: BatchNormalization, current shape: [[None, 64]]\n",
      "Name: quantized_relu\n",
      "Layer name: dense_act_1, layer type: Activation, current shape: [[None, 64]]\n",
      "Layer name: output_dense, layer type: Dense, current shape: [[None, 64]]\n",
      "Layer name: output_softmax, layer type: Softmax, current shape: [[None, 10]]\n",
      "Creating HLS model\n",
      "WARNING: Invalid ReuseFactor=10 with \"Resource\" strategy in layer \"fused_convbn_0\". Using ReuseFactor=9 instead. Valid ReuseFactor(s): 3,9,27,54,108,216,432.\n",
      "WARNING: Invalid ReuseFactor=40 with \"Resource\" strategy in layer \"fused_convbn_1\". Using ReuseFactor=36 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,36,48,72,144,288,576,1152,2304.\n",
      "WARNING: Invalid ReuseFactor=40 with \"Resource\" strategy in layer \"fused_convbn_2\". Using ReuseFactor=36 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,36,48,72,144,288,432,576,864,1152,1728,3456.\n",
      "WARNING: Invalid ReuseFactor=650 with \"Resource\" strategy in layer \"dense_0\". Using ReuseFactor=672 instead. Valid ReuseFactor(s): 2,3,4,6,8,12,16,24,32,48,96,192,288,576,672,1344,2016,4032.\n",
      "WARNING: Invalid ReuseFactor=300 with \"Resource\" strategy in layer \"dense_1\". Using ReuseFactor=336 instead. Valid ReuseFactor(s): 2,3,6,7,14,21,42,84,168,336,672,1344,2688.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"output_dense\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,320,640.\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "hls_config['Model'] = {}\n",
    "hls_config['Model']['ReuseFactor'] = 2\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config['LayerName']['fused_convbn_0']['ReuseFactor'] = 9\n",
    "hls_config['LayerName']['fused_convbn_1']['ReuseFactor'] = 36\n",
    "hls_config['LayerName']['fused_convbn_2']['ReuseFactor'] = 36\n",
    "hls_config['LayerName']['dense_0']['ReuseFactor'] = 672\n",
    "hls_config['LayerName']['dense_1']['ReuseFactor'] = 366\n",
    "hls_config['LayerName']['output_dense']['ReuseFactor'] = 128\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model=model,\n",
    "                                                       backend='VivadoAccelerator',\n",
    "                                                       io_type='io_stream', \n",
    "                                                       device='pynq-z2',\n",
    "                                                       hls_config=hls_config, \n",
    "                                                       output_dir=\"pynq_cnn_pynq-z2\")\n",
    "\n",
    "hls_model.build(csim=False, synth=True, export=True)\n",
    "hls4ml.report.read_vivado_report('pynq_cnn_pynq-z2/')\n",
    "\n",
    "hls4ml.templates.VivadoAcceleratorBackend.make_bitfile(hls_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = X_test[:3000]\n",
    "Y_test_reduced = Y_test[:3000]\n",
    "\n",
    "y_predict        = model.predict(X_test_reduced)\n",
    "y_predict_hls4ml = hls_model.predict(np.ascontiguousarray(X_test_reduced))\n",
    "\n",
    "import plotting\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plotROC(Y, y_pred, y_pred_hls4ml, label=\"Model\"):\n",
    "    \n",
    "    accuracy_keras  = float(accuracy_score (np.argmax(Y,axis=1), np.argmax(y_pred,axis=1)))\n",
    "    accuracy_hls4ml = float(accuracy_score (np.argmax(Y,axis=1), np.argmax(y_pred_hls4ml,axis=1)))\n",
    "\n",
    "    print(\"Accuracy Keras:  {}\".format(accuracy_keras))\n",
    "    print(\"Accuracy hls4ml: {}\".format(accuracy_hls4ml))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9, 9))\n",
    "    _ = plotting.makeRoc(Y, y_pred, labels=['%i'%nr for nr in range(n_classes)])\n",
    "    plt.gca().set_prop_cycle(None) # reset the colors\n",
    "    _ = plotting.makeRoc(Y, y_pred_hls4ml, labels=['%i'%nr for nr in range(n_classes)], linestyle='--')\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    lines = [Line2D([0], [0], ls='-'),\n",
    "             Line2D([0], [0], ls='--')]\n",
    "    from matplotlib.legend import Legend\n",
    "    leg = Legend(ax, lines, labels=['Keras', 'hls4ml'],\n",
    "                loc='lower right', frameon=False)\n",
    "    ax.add_artist(leg)\n",
    "    plt.figtext(0.2, 0.38,label, wrap=True, horizontalalignment='left',verticalalignment='center')\n",
    "    plt.ylim(0.01,1.)\n",
    "    plt.xlim(0.7,1.)\n",
    "\n",
    "# Plot the ROC   \n",
    "plotROC(Y_test_reduced,y_predict,y_predict_hls4ml,label=\"QKeras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReports(indir):\n",
    "    data_ = {}\n",
    "    \n",
    "    report_vsynth = Path('{}/vivado_synth.rpt'.format(indir))\n",
    "    report_csynth = Path('{}/myproject_prj/solution1/syn/report/myproject_csynth.rpt'.format(indir))\n",
    "    \n",
    "    if report_vsynth.is_file() and report_csynth.is_file():\n",
    "        print('Found valid vsynth and synth in {}! Fetching numbers'.format(indir))\n",
    "        \n",
    "        # Get the resources from the logic synthesis report \n",
    "        with report_vsynth.open() as report:\n",
    "          lines = np.array(report.readlines())\n",
    "          data_['lut']     = int(lines[np.array(['CLB LUTs*' in line for line in lines])][0].split('|')[2])\n",
    "          data_['ff']      = int(lines[np.array(['CLB Registers' in line for line in lines])][0].split('|')[2])\n",
    "          data_['bram']    = float(lines[np.array(['Block RAM Tile' in line for line in lines])][0].split('|')[2])\n",
    "          data_['dsp']     = int(lines[np.array(['DSPs' in line for line in lines])][0].split('|')[2])\n",
    "          data_['lut_rel'] = float(lines[np.array(['CLB LUTs*' in line for line in lines])][0].split('|')[5])\n",
    "          data_['ff_rel']  = float(lines[np.array(['CLB Registers' in line for line in lines])][0].split('|')[5])\n",
    "          data_['bram_rel']= float(lines[np.array(['Block RAM Tile' in line for line in lines])][0].split('|')[5])\n",
    "          data_['dsp_rel'] = float(lines[np.array(['DSPs' in line for line in lines])][0].split('|')[5])\n",
    "        \n",
    "        with report_csynth.open() as report:\n",
    "          lines = np.array(report.readlines())\n",
    "          lat_line = lines[np.argwhere(np.array(['Latency (cycles)' in line for line in lines])).flatten()[0] + 3]\n",
    "          data_['latency_clks'] = int(lat_line.split('|')[2])\n",
    "          data_['latency_mus']  = float(lat_line.split('|')[2])*5.0/1000.\n",
    "          data_['latency_ii']   = int(lat_line.split('|')[6])\n",
    "    \n",
    "    return data_\n",
    "\n",
    "from pathlib import Path\n",
    "import pprint \n",
    "\n",
    "data = getReports('pynq_cnn')\n",
    "\n",
    "print(\"\\n Resource usage and latency: PYNQ CNN\")\n",
    "pprint.pprint(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the big guy:\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "hls_config['Model'] = {}\n",
    "hls_config['Model']['ReuseFactor'] = 1\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model=model,\n",
    "                                                       backend='VivadoAccelerator',\n",
    "                                                       io_type='io_stream', \n",
    "                                                       device='zcu102',\n",
    "                                                       hls_config=hls_config, \n",
    "                                                       output_dir=\"pynq_cnn_zcu102\")\n",
    "\n",
    "hls_model.build(csim=False, synth=True, export=True)\n",
    "hls4ml.report.read_vivado_report('pynq_cnn_zcu102/')\n",
    "\n",
    "hls4ml.templates.VivadoAcceleratorBackend.make_bitfile(hls_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_hls4ml = hls_model.predict(np.ascontiguousarray(X_test_reduced))\n",
    "plotROC(Y_test_reduced,y_predict,y_predict_hls4ml,label=\"zcu102\") \n",
    "\n",
    "data = getReports('pynq_cnn_zcu102')\n",
    "\n",
    "print(\"\\n Resource usage and latency: zcu102 CNN\")\n",
    "pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "hls4ml-pynq-tutorial",
   "language": "python",
   "name": "hls4ml-pynq-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
